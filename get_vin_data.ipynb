{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ypKBxUtr79f5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time, random\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\work\\myrepo\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_headers = [\n",
        "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14\",\n",
        "    \"Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)\",\n",
        "    'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11',\n",
        "    'Opera/9.25 (Windows NT 5.1; U; en)',\n",
        "    'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)',\n",
        "    'Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)',\n",
        "    'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12',\n",
        "    'Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9',\n",
        "    \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7\",\n",
        "    \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0 \"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v4m720r8MRH",
        "outputId": "e802e42d-7c3f-44a1-9000-b0a5e1a98c89"
      },
      "outputs": [],
      "source": [
        "def get_url_list():\n",
        "  page_html = requests.get('https://vin17.com/',headers={'User-Agent':random.choice(my_headers)})\n",
        "  if page_html.status_code != 200:\n",
        "    raise Exception(\"error\")\n",
        "      #print(page_html.text)\n",
        "\n",
        "      #解析整个页面获取所有vin对应的urls\n",
        "      #返回urls\n",
        "  else:\n",
        "    print(\"访问网站成功:\",page_html.status_code)\n",
        "\n",
        "  soup = BeautifulSoup(page_html.content, 'html.parser')\n",
        "      #print(soup.prettify())  #打印解析后的html\n",
        "\n",
        "    #下载所有htmls\n",
        "  url_list = []\n",
        "\n",
        "  for div in (soup.find(\"div\",  class_ = 'history-box').find_all(\"div\", class_ = 'col-md-3 col-sm-6')):\n",
        "    url = div.find(\"a\").get(\"href\")\n",
        "    url_list.append(url)\n",
        "  print(\"已获得页面链接\")\n",
        "  #print(url_list)\n",
        "  return url_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WeH2R13wAoRv"
      },
      "outputs": [],
      "source": [
        "#解析单页html\n",
        "#返回\n",
        "'''\n",
        "{\n",
        "  \"vincode\": \"WBAKC810XCDV57019\",     #车架号\n",
        "  \"brand\": \"宝马\",                #品牌\n",
        "  \"manufacturer\": \"宝马(进口)\",   #制造厂\n",
        "  \"modelType\": \"宝马7系\",        #车型\n",
        "  \"cc\": \"4395\",                 #发动机排量\n",
        "  \"bodyType\": \"4门5座三厢车\",    #车身型式\n",
        "  \"modelYear\": \"2011\",          #年款\n",
        "  \"engineCode\": \"N63B44A\",      #发动机型号\n",
        "  \"Vehicle_data\": [             #对应车款数据\n",
        "    {\"vehicleType\": \"宝马7系 2011款 750Li xDrive\",\n",
        "    \"modelYear\": \"2011\",\n",
        "    \"gearbox\": \"自动\",\n",
        "    \"power\": \"300\",\n",
        "    \"cc\": \"4395\",\n",
        "    \"engineCode\": \"N63B44A\",\n",
        "    \"fuel\": \"汽油\",\n",
        "    \"bodyType\": \"4门5座三厢车\",\n",
        "    \"driveMode\": \"前置四驱\"\n",
        "    },\n",
        "    ...,\n",
        "    {}\n",
        "    ]\n",
        "}\n",
        "'''\n",
        "def parse_single_html(url):\n",
        "  html = requests.get(url, headers={'User-Agent':random.choice(my_headers)},)\n",
        "  if html.status_code != 200:\n",
        "    print(\"html download error: \", url)\n",
        "  else:\n",
        "    print(\"download html success: \", url)\n",
        "\n",
        "  soup2 = BeautifulSoup(html.content, 'html.parser')\n",
        "\n",
        "  #获取VIN车架号 https://vin17.com/vin/LSVCA6F23P2012225\n",
        "  vin_data_dict = {}\n",
        "  arr = url.split(\"/\")\n",
        "  vincode = arr[-1]\n",
        "\n",
        "  vin_data_dict['vincode'] = vincode\n",
        "  #获取WMI/VDS/VIS\n",
        "  #WMI = soup2.find(\"span\", class_=\"fir\").getText()\n",
        "  #VDS = soup2.find(\"span\", class_=\"sec\").getText()\n",
        "  #VIS = soup2.find(\"span\", class_=\"thi\").getText()\n",
        "  \n",
        "  #获取汽车详细信息\n",
        "  vin_data_list = soup2.find(\"table\", class_=\"table table-bordered table-sm car-table mb-0\").find_all(\"span\", attrs={'id':True})\n",
        "  for vin_data_item in vin_data_list:\n",
        "    key = vin_data_item.get(\"id\")\n",
        "    vin_data_dict[key] = vin_data_item.text\n",
        "  #print(vin_data_dict)\n",
        "    \n",
        "  #获取对应车款数据 Vehicle data\n",
        "  keys_list = ['vehicleType', 'modelYear','gearbox', 'power','cc','engineCode', 'fuel', 'bodyType','driveMode']\n",
        "  Vehicle_data_list = []\n",
        "  Vehicle_data_dict = {}\n",
        "  vehicle_list = soup2.find_all(\"tr\", attrs= {\"data-id\":True})\n",
        "\n",
        "  for vehicle_data_tr in vehicle_list:\n",
        "    data_list = vehicle_data_tr.find_all(\"td\")\n",
        "    for index, data in enumerate(data_list):\n",
        "      if index == 9:\n",
        "        break\n",
        "      else:\n",
        "        key = keys_list[index]\n",
        "        Vehicle_data_dict[key] = data.text.replace('\\xa0', ' ')\n",
        "    #将数据添加到列表中\n",
        "    Vehicle_data_list.append(Vehicle_data_dict)\n",
        "  #print(Vehicle_data_list)\n",
        "  \n",
        "  vin_data_dict['Vehicle_data'] = Vehicle_data_list\n",
        "\n",
        "  print(\"parse success vin: \",vincode)\n",
        "  return vin_data_dict\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#测试&存储\n",
        "def vin_spider_start():\n",
        "    result_list = []\n",
        "    data_list = []\n",
        "    url_list = get_url_list()\n",
        "    try:\n",
        "        for url in url_list:\n",
        "            result_list.append(parse_single_html(url))\n",
        "            time.sleep(5)\n",
        "\n",
        "    except Exception as result:\n",
        "        print(result)\n",
        "        print(\"已达到每日限制\")\n",
        "    finally:\n",
        "        #如何已存在文件\n",
        "        if os.path.exists('vin_data.json'):\n",
        "            with open('vin_data.json', 'r', encoding='utf-8') as file:\n",
        "                str_file = file.read()\n",
        "                if str_file == 0:\n",
        "                    print(\"内容为空\")\n",
        "                else:\n",
        "                    data_list = json.loads(str_file)\n",
        "                    #print(data_list)\n",
        "\n",
        "        data_list.extend(result_list)\n",
        "        with open('vin_data.json', 'w', encoding='utf-8') as file:\n",
        "            json.dump(data_list, file, ensure_ascii=False, indent=2)\n",
        "            print(\"write data to file success\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "访问网站成功: 200\n",
            "已获得页面链接\n",
            "download html success:  https://vin17.com/vin/LSVMB6C61MN020908\n",
            "'NoneType' object has no attribute 'find_all'\n",
            "已达到每日限制\n",
            "vindata write to file success\n"
          ]
        }
      ],
      "source": [
        "vin_spider_start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "with open('vin_data.json', 'r', encoding='utf-8') as file:\n",
        "    str_file = file.read()\n",
        "    if  len(str_file) > 0:\n",
        "        tmp = json.loads(str_file)\n",
        "    print(len(tmp))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
